after marco+gemma's meeting Jan 13 2016

MODELS TO IMPLEMENT FOR THE WHITE CAT EXPERIMENT

NB1: each model can take image sets of different sizes, e.g. 3 to 7
images (motivation: "magical number 7"... all the way down to 3), or 2
to 10, or whatever; in the implementation of the soft retrieval
method(s), this can simply be handled by always passing the max number
of image vectors, where the set is padded with 0-vectors

NB2: NAMEs below are the names given to the model in our code (not
assigned to the baseline, as it will require a separate codebase)

NB3: outline models below ignore non-linearities; we have to discuss
those: they might be considered as hyperparameters to be experimented
with

Inputs: CNN-based image representations i_i, word2vec word representation w


* baseline: hard-coded retrieval in multimodal space

phase 1: train multimodal word/image embeddings

for a large set of words and pictures of the concepts they denote:

map word vector w to multimodal vector m_w with matrix W
map corresponding image vector i to multimodal vector m_i_r with matrix I
map set of unrelated image vectors u_i ... u_n to multimodal vectors m_i_u
use max margin objective to maximize similarity (dot product) of m_w and m_i_r vs m_w and all the m_i_us

phase 2: hard-coded retrieval (on test word+image set samples)

use I to map image vectors i_1 ... i_n to separate multimodal vectors m_i_1 ... m_i_n
use W to map word vector w to multimodal vector m_w
take dot product of m_w with each of m_i_1 ... m_i_n
return index of multimodal image vector with largest dot product

* soft retrieval via reference vectors
NAME: reference_retrieval # NB: to be updated in code!

map image vectors i_1 ... i_n to separate reference vectors r_1 ... r_n (sharing parameters)
map word vector w to query vector q
construct vector p by taking dot product of q with each r_1 ... r_n and softmaxing resulting values
compare p to one-hot vector recording position of correct image vector with log-likelihood objective

# NB: at training time, it is assumed that there is one and only one
# correct image; once the model it is trained it can be presented
# image sets with no correct image, or more than one: a threshold on
# the max value of the p vector can be estimated to allow the model a
# "no response" option (when max(p) is below the threshold)


