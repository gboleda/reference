-- preambles

require('nngraph')
require('../LinearNB') -- for linear mappings without bias

cmd = torch.CmdLine()
-- model file to be read
cmd:option('--model_file','', 'name of file storing trained model generated by lent-and-returned-main.lua')
-- data files and data characteristics
cmd:option('--word_embedding_file','','word embedding file (with word vectors; first field word, rest of the fields vector values)... must be coherent with representations used at model training!')
cmd:option('--image_embedding_file','','image embedding file (with visual vectors; first field word and image, rest of the fields vector values)... must be coherent with representations used at model training!')
cmd:option('--normalize_embeddings',0, 'whether to normalize word and image representations, set to 1 to normalize: must be coherent with choice at model training')
cmd:option('--input_sequence_cardinality', 0, 'number of object tokens in a sequence')
cmd:option('--test_file','','name of test file; format: same as that of protocol files used for training')
cmd:option('--test_set_size',0, 'test set size')
-- output file
cmd:option('--output_guesses_file','','if this file is defined, we print to it, as separated space-delimited columns, the index the model returned as its guess for each test item, and the corresponding log probability')
opt = cmd:parse(arg or {})
print(opt)

local output_guesses_file=nil
if opt.output_guesses_file~='' then
   output_guesses_file=opt.output_guesses_file
end

-- other general parameters
-- chunks to read files into
BUFSIZE = 2^23 -- 1MB


-- ****** loading models, data handling functions ******

print('reading the models file')
dofile('model.lua')

print('reading the data processing file')
dofile('data.lua')

-- ****** input data reading ******

-- reading word embeddings
word_embeddings,t_input_size=load_embeddings(opt.word_embedding_file,opt.normalize_embeddings)
--reading image embeddings
image_embeddings,v_input_size=load_embeddings(opt.image_embedding_file,opt.normalize_embeddings)
-- reading in the test data
input_table,gold_index_list=
   create_input_structures_from_file(
      opt.test_file,
      opt.test_set_size,
      t_input_size,
      v_input_size,
      opt.input_sequence_cardinality)

-- ****** model reading ******

print('reading in the model from file ' .. opt.model_file)
model = torch.load(opt.model_file)

-- *** computing model predictions and accuracy

print('computing model predictions on test data')
-- passing all test samples through the trained network
local model_predictions=model:forward(input_table)

print('computing accuracy')


-- to compute accuracy, we first retrieve list of indices of items
-- that were preferred by the model
local model_guesses_probs,model_guesses_indices=torch.max(model_predictions,2)
-- we then count how often these guesses are the same as the gold
-- (and thus the difference is 0) (note conversions to long because
-- model_guesses_indices is long tensor)
local hit_count=torch.sum(torch.eq(gold_index_list:long(),model_guesses_indices))
-- normalizing accuracy by test set size
local accuracy=hit_count/opt.test_set_size

print('test set accuracy is ' .. accuracy)

--if requested, print guesses, their log probs and the overall prob distribution 
--to file
if output_guesses_file then
   print("writing individual model predictions to file " .. output_guesses_file)

   local f = io.open(output_guesses_file,"w")
   for i=1,model_guesses_probs:size(1) do
      f:write(model_guesses_indices[i][1]," ",model_guesses_probs[i][1],"\n")
   end
   f:flush()
   f.close()
end
